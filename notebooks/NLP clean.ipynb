{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9181560-d1de-4ec1-8d89-c5b36dd0263a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7d3ac9-feb3-4e17-9a9a-687219448d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emanuel\\anaconda3\\envs\\SER\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Set current working directory to parent folder\n",
    "import os\n",
    "os.chdir(os.path.abspath(\"..\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from transformers import WhisperTokenizer\n",
    "from src.traductores import obtener_emocion\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization, Embedding, GlobalAveragePooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Archivos importantes y paths\n",
    "df_annotations = pd.read_excel('data/annotations.xlsx')\n",
    "\n",
    "# Omitimos todos los audios en development\n",
    "df_annotations = df_annotations[df_annotations['Type'] != 'Development'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54cda7-30ee-45d0-b357-4564ec082d24",
   "metadata": {},
   "source": [
    "# Preparación dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eed165-0d7b-414b-860c-7f972f51cfcf",
   "metadata": {},
   "source": [
    "## Tamaño vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff4789e-9d15-438d-bb2c-7178c727f532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Obtener tamaño total del vocabulario\n",
    "all_tokens = WhisperTokenizer.from_pretrained(\"openai/whisper-large\").get_vocab()\n",
    "max_value = max(zip(all_tokens.values(), all_tokens.keys()))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee91fea6-62ff-49a0-a134-d2343662ec4a",
   "metadata": {},
   "source": [
    "## Creación dataset de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd3d160d-2705-42eb-b819-0ec9c125b2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Audio</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>MSP-Conversation_0002</td>\n",
       "      <td>It's our honor to talk about important issues...</td>\n",
       "      <td>[467, 311, 527, 5968, 281, 751, 466, 1021, 266...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>MSP-Conversation_0002</td>\n",
       "      <td>The foundation of our show, Heart of the Matt...</td>\n",
       "      <td>[440, 7030, 295, 527, 855, 11, 13569, 295, 264...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>MSP-Conversation_0002</td>\n",
       "      <td>Important issues and why they should be on ou...</td>\n",
       "      <td>[42908, 2663, 293, 983, 436, 820, 312, 322, 52...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>MSP-Conversation_0002</td>\n",
       "      <td>Looking at things as right versus wrong inste...</td>\n",
       "      <td>[11053, 412, 721, 382, 558, 5717, 2085, 2602, ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>MSP-Conversation_0002</td>\n",
       "      <td>And sharing stories with real people's experi...</td>\n",
       "      <td>[400, 5414, 3676, 365, 957, 561, 311, 5235, 37...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                  Audio  \\\n",
       "0  0.0  MSP-Conversation_0002   \n",
       "1  1.0  MSP-Conversation_0002   \n",
       "2  2.0  MSP-Conversation_0002   \n",
       "3  3.0  MSP-Conversation_0002   \n",
       "4  4.0  MSP-Conversation_0002   \n",
       "\n",
       "                                                Text  \\\n",
       "0   It's our honor to talk about important issues...   \n",
       "1   The foundation of our show, Heart of the Matt...   \n",
       "2   Important issues and why they should be on ou...   \n",
       "3   Looking at things as right versus wrong inste...   \n",
       "4   And sharing stories with real people's experi...   \n",
       "\n",
       "                                              Tokens  num_words  \n",
       "0  [467, 311, 527, 5968, 281, 751, 466, 1021, 266...         16  \n",
       "1  [440, 7030, 295, 527, 855, 11, 13569, 295, 264...         13  \n",
       "2  [42908, 2663, 293, 983, 436, 820, 312, 322, 52...         11  \n",
       "3  [11053, 412, 721, 382, 558, 5717, 2085, 2602, ...         12  \n",
       "4  [400, 5414, 3676, 365, 957, 561, 311, 5235, 37...         19  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación del dataset de texto\n",
    "df_texto = pd.DataFrame()\n",
    "\n",
    "df_texto.loc[0, 'id'] = 0\n",
    "\n",
    "for file in os.listdir('data/TRANSCRIPCIONES/WHISPER'):\n",
    "    with open(f'data/TRANSCRIPCIONES/WHISPER/{file}', 'r') as f: \n",
    "        data = json.load(f)\n",
    "    \n",
    "    start = max(df_texto.index)\n",
    "    \n",
    "    for i in range(len(data['segments'])):\n",
    "        df_texto.at[i + start, 'Audio'] = file[:-5]\n",
    "        df_texto.at[i + start, 'id'] = int(data['segments'][i]['id'])\n",
    "        df_texto.at[i + start, 'Text'] = data['segments'][i]['text']\n",
    "        df_texto.at[i + start, 'Tokens'] = str(data['segments'][i]['tokens'][1:-1])\n",
    "\n",
    "\n",
    "# Agregamos cantidad de palabras\n",
    "df_texto['num_words'] = df_texto['Text'].apply(lambda x:len(str(x).split()))\n",
    "\n",
    "df_texto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20576744-0399-42bf-ab5d-23aa77e8f663",
   "metadata": {},
   "source": [
    "## Concatenar Objetivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729a9851-70b3-4882-b645-77b9f8583fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener objetivos\n",
    "with open(f'data/MODELS/v3/objetivos.json', 'r') as f: objetivos = json.load(f)\n",
    "\n",
    "df_objetivos = pd.DataFrame()\n",
    "\n",
    "for _key in objetivos:\n",
    "    df_temp = pd.DataFrame({'Audio': _key[:21], 'indice': objetivos[_key]['indice'], 'targets': objetivos[_key]['targets']})\n",
    "    df_objetivos = pd.concat([df_temp, df_objetivos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0db8bcd-7dda-40a9-886e-1d4893b463e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "df_texto['id'] = df_texto['id'].astype(int)\n",
    "df_final = pd.merge(df_texto, df_objetivos, how = 'left', right_on = ['Audio','indice'], left_on = ['Audio','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbbe7498-7446-4966-a438-7a3576d02e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saco los de development que estan en el texto\n",
    "df_final = df_final.dropna(subset = 'targets')\n",
    "\n",
    "# Agrego emoción categoróica\n",
    "df_final['Target'] = [obtener_emocion(i[0],i[1],i[2], mapping = 'Ekman') for i in df_final['targets']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a3ddf4-0adb-421c-b13b-0c134d57933a",
   "metadata": {},
   "source": [
    "## Borrar ids con 0 palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dce83d2d-b947-4169-bf6c-5329031f987c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Audio</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>num_words</th>\n",
       "      <th>indice</th>\n",
       "      <th>targets</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83341</th>\n",
       "      <td>726</td>\n",
       "      <td>MSP-Conversation_2281</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>[7.339746733985966, 27.070739517689248, 36.032...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                  Audio Text Tokens  num_words  indice  \\\n",
       "83341  726  MSP-Conversation_2281          []          0   726.0   \n",
       "\n",
       "                                                 targets   Target  \n",
       "83341  [7.339746733985966, 27.070739517689248, 36.032...  neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[df_final['num_words'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43edc07-3eca-4758-9a03-0ca071606d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final[df_final['num_words'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bda287-7516-4e3f-8cb8-87823a528ffa",
   "metadata": {},
   "source": [
    "## Convertir tokens en formato lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e94e3671-6be1-41a9-a4f4-ad3dea505c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir_strarray_a_array(filas):\n",
    "    x = []\n",
    "    for fila in filas:\n",
    "        fila = fila.replace('[','').replace(']','').split(',')\n",
    "        x.append([int(i) for i in fila])\n",
    "\n",
    "    return x\n",
    "\n",
    "df_final['Tokens'] = convertir_strarray_a_array(df_final['Tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ca78c-2bf0-431d-982e-21bbdb53c0a2",
   "metadata": {},
   "source": [
    "## Concatenar tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a6c4e7e-b49e-4ae9-8f86-3a88204f8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Audio_Name'] = df_final['Audio'] + '.wav'\n",
    "\n",
    "df_final = pd.merge(df_final, \n",
    "                    df_annotations[['Audio_Name','Type']].drop_duplicates(), \n",
    "                    how = 'left', \n",
    "                    left_on = 'Audio_Name', \n",
    "                    right_on = 'Audio_Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ade514-dbe6-40ed-af27-7d7cbe7a598e",
   "metadata": {},
   "source": [
    "# Pre Procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96c4dbf8-9ec7-4d65-ab32-24ad3a794da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay que investigar por que hay targets na\n",
    "df_final = df_final[~df_final['Target'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a94403a-3a7e-43d9-9bc4-2b877ff752d3",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4da1f288-0d39-4bdf-8651-48de95d16894",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [i for i in df_final[df_final['Type'] == 'Train']['Tokens'].values]\n",
    "x_test = [i for i in df_final[df_final['Type'] == 'Test']['Tokens'].values]\n",
    "\n",
    "x_train = pad_sequences(x_train, padding='post',maxlen = max(df_final['num_words']))\n",
    "x_test = pad_sequences(x_test, padding='post',maxlen = max(df_final['num_words']))\n",
    "\n",
    "# Encoder de las emociones\n",
    "Y = df_final['Target'].values\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(np.array(Y).reshape(-1,1))\n",
    "\n",
    "y_train = df_final[df_final['Type'] == 'Train']['Target'].values\n",
    "y_test = df_final[df_final['Type'] == 'Test']['Target'].values\n",
    "y_train = encoder.transform(np.array(y_train).reshape(-1,1)).toarray()\n",
    "y_test = encoder.transform(np.array(y_test).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab94bcb-ca1d-4e09-9fe3-3dd3227add9f",
   "metadata": {},
   "source": [
    "## Modelo todas las emocioens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54908ff5-d898-4d46-b2b9-f3f10db17d69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1595/1595 [==============================] - 21s 13ms/step - loss: 1.0321 - accuracy: 0.6583 - val_loss: 1.0598 - val_accuracy: 0.6596\n",
      "Epoch 2/50\n",
      "1595/1595 [==============================] - 20s 13ms/step - loss: 0.9990 - accuracy: 0.6586 - val_loss: 1.0456 - val_accuracy: 0.6596\n",
      "Epoch 3/50\n",
      "1595/1595 [==============================] - 21s 13ms/step - loss: 0.9511 - accuracy: 0.6646 - val_loss: 1.0655 - val_accuracy: 0.6534\n",
      "Epoch 4/50\n",
      "1595/1595 [==============================] - 21s 13ms/step - loss: 0.9179 - accuracy: 0.6736 - val_loss: 1.1218 - val_accuracy: 0.6521\n",
      "Epoch 5/50\n",
      "1595/1595 [==============================] - 21s 13ms/step - loss: 0.8965 - accuracy: 0.6823 - val_loss: 1.1214 - val_accuracy: 0.6460\n",
      "Epoch 6/50\n",
      "1595/1595 [==============================] - 22s 14ms/step - loss: 0.8802 - accuracy: 0.6878 - val_loss: 1.1789 - val_accuracy: 0.6091\n",
      "Epoch 7/50\n",
      "1595/1595 [==============================] - 22s 14ms/step - loss: 0.8660 - accuracy: 0.6929 - val_loss: 1.1774 - val_accuracy: 0.6242\n",
      "Epoch 8/50\n",
      "1595/1595 [==============================] - 22s 14ms/step - loss: 0.8569 - accuracy: 0.6951 - val_loss: 1.2491 - val_accuracy: 0.6252\n",
      "Epoch 9/50\n",
      "1595/1595 [==============================] - 21s 13ms/step - loss: 0.8489 - accuracy: 0.6971 - val_loss: 1.2029 - val_accuracy: 0.6309\n",
      "Epoch 10/50\n",
      "1595/1595 [==============================] - 22s 14ms/step - loss: 0.8401 - accuracy: 0.7006 - val_loss: 1.2270 - val_accuracy: 0.6256\n",
      "Epoch 11/50\n",
      " 317/1595 [====>.........................] - ETA: 14s - loss: 0.8133 - accuracy: 0.7048"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m rlrp \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0000001\u001b[39m)\n\u001b[0;32m     15\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SER\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SER\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SER\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SER\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SER\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SER\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SER\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SER\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SER\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = max_value, output_dim = 16, input_length=x_train.shape[1]))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.4, verbose=0, patience=5, min_lr=0.0000001)\n",
    "es = EarlyStopping(monitor='val_loss', patience=50)\n",
    "model.fit(x_train, y_train, epochs= 50, validation_data=(x_test, y_test), callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decee4e1-3f15-4bee-9bff-8484c591aae5",
   "metadata": {},
   "source": [
    "## Modelo flag neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72da2b45-1634-4759-aa5f-928fd356c48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1543/1543 [==============================] - 20s 13ms/step - loss: 0.6263 - accuracy: 0.6806 - val_loss: 0.6252 - val_accuracy: 0.6774\n",
      "Epoch 2/50\n",
      "1543/1543 [==============================] - 20s 13ms/step - loss: 0.5967 - accuracy: 0.6839 - val_loss: 0.6256 - val_accuracy: 0.6769\n",
      "Epoch 3/50\n",
      "1543/1543 [==============================] - 20s 13ms/step - loss: 0.5533 - accuracy: 0.7145 - val_loss: 0.6572 - val_accuracy: 0.6687\n",
      "Epoch 4/50\n",
      "1543/1543 [==============================] - 20s 13ms/step - loss: 0.5215 - accuracy: 0.7368 - val_loss: 0.6604 - val_accuracy: 0.6596\n",
      "Epoch 5/50\n",
      "1543/1543 [==============================] - 24s 16ms/step - loss: 0.5001 - accuracy: 0.7504 - val_loss: 0.7099 - val_accuracy: 0.6176\n",
      "Epoch 6/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.4820 - accuracy: 0.7585 - val_loss: 0.6730 - val_accuracy: 0.6627\n",
      "Epoch 7/50\n",
      "1543/1543 [==============================] - 22s 14ms/step - loss: 0.4690 - accuracy: 0.7642 - val_loss: 0.7871 - val_accuracy: 0.6592\n",
      "Epoch 8/50\n",
      "1543/1543 [==============================] - 21s 14ms/step - loss: 0.4581 - accuracy: 0.7696 - val_loss: 0.7372 - val_accuracy: 0.6654\n",
      "Epoch 9/50\n",
      "1543/1543 [==============================] - 21s 14ms/step - loss: 0.4484 - accuracy: 0.7741 - val_loss: 0.8339 - val_accuracy: 0.6194\n",
      "Epoch 10/50\n",
      "1543/1543 [==============================] - 22s 14ms/step - loss: 0.4384 - accuracy: 0.7773 - val_loss: 0.7841 - val_accuracy: 0.6523\n",
      "Epoch 11/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.4307 - accuracy: 0.7802 - val_loss: 0.8125 - val_accuracy: 0.6515\n",
      "Epoch 12/50\n",
      "1543/1543 [==============================] - 22s 15ms/step - loss: 0.4208 - accuracy: 0.7841 - val_loss: 1.0424 - val_accuracy: 0.6134\n",
      "Epoch 13/50\n",
      "1543/1543 [==============================] - 22s 15ms/step - loss: 0.4134 - accuracy: 0.7867 - val_loss: 1.1132 - val_accuracy: 0.6346\n",
      "Epoch 14/50\n",
      "1543/1543 [==============================] - 25s 16ms/step - loss: 0.4084 - accuracy: 0.7894 - val_loss: 0.9557 - val_accuracy: 0.6192\n",
      "Epoch 15/50\n",
      "1543/1543 [==============================] - 21s 14ms/step - loss: 0.3998 - accuracy: 0.7928 - val_loss: 1.1441 - val_accuracy: 0.6528\n",
      "Epoch 16/50\n",
      "1543/1543 [==============================] - 21s 13ms/step - loss: 0.3911 - accuracy: 0.7967 - val_loss: 1.1439 - val_accuracy: 0.6593\n",
      "Epoch 17/50\n",
      "1543/1543 [==============================] - 21s 13ms/step - loss: 0.3877 - accuracy: 0.7961 - val_loss: 1.1521 - val_accuracy: 0.6393\n",
      "Epoch 18/50\n",
      "1543/1543 [==============================] - 21s 14ms/step - loss: 0.3803 - accuracy: 0.8007 - val_loss: 1.4174 - val_accuracy: 0.6292\n",
      "Epoch 19/50\n",
      "1543/1543 [==============================] - 22s 14ms/step - loss: 0.3756 - accuracy: 0.8022 - val_loss: 1.4064 - val_accuracy: 0.6168\n",
      "Epoch 20/50\n",
      "1543/1543 [==============================] - 21s 13ms/step - loss: 0.3688 - accuracy: 0.8063 - val_loss: 1.3510 - val_accuracy: 0.6370\n",
      "Epoch 21/50\n",
      "1543/1543 [==============================] - 20s 13ms/step - loss: 0.3644 - accuracy: 0.8073 - val_loss: 1.7024 - val_accuracy: 0.6298\n",
      "Epoch 22/50\n",
      "1543/1543 [==============================] - 21s 14ms/step - loss: 0.3568 - accuracy: 0.8111 - val_loss: 1.3434 - val_accuracy: 0.6209\n",
      "Epoch 23/50\n",
      "1543/1543 [==============================] - 20s 13ms/step - loss: 0.3536 - accuracy: 0.8131 - val_loss: 1.3965 - val_accuracy: 0.6274\n",
      "Epoch 24/50\n",
      "1543/1543 [==============================] - 22s 15ms/step - loss: 0.3465 - accuracy: 0.8181 - val_loss: 1.9319 - val_accuracy: 0.6047\n",
      "Epoch 25/50\n",
      "1543/1543 [==============================] - 25s 16ms/step - loss: 0.3398 - accuracy: 0.8211 - val_loss: 2.0123 - val_accuracy: 0.5972\n",
      "Epoch 26/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.3355 - accuracy: 0.8271 - val_loss: 1.9151 - val_accuracy: 0.5964\n",
      "Epoch 27/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.3331 - accuracy: 0.8274 - val_loss: 2.2759 - val_accuracy: 0.5983\n",
      "Epoch 28/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.3266 - accuracy: 0.8306 - val_loss: 2.2020 - val_accuracy: 0.5996\n",
      "Epoch 29/50\n",
      "1543/1543 [==============================] - 24s 16ms/step - loss: 0.3230 - accuracy: 0.8344 - val_loss: 2.0968 - val_accuracy: 0.6295\n",
      "Epoch 30/50\n",
      "1543/1543 [==============================] - 24s 15ms/step - loss: 0.3168 - accuracy: 0.8378 - val_loss: 2.0119 - val_accuracy: 0.6223\n",
      "Epoch 31/50\n",
      "1543/1543 [==============================] - 24s 15ms/step - loss: 0.3155 - accuracy: 0.8390 - val_loss: 2.8603 - val_accuracy: 0.6125\n",
      "Epoch 32/50\n",
      "1543/1543 [==============================] - 25s 16ms/step - loss: 0.3090 - accuracy: 0.8424 - val_loss: 2.7276 - val_accuracy: 0.6106\n",
      "Epoch 33/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.3072 - accuracy: 0.8443 - val_loss: 2.4700 - val_accuracy: 0.6329\n",
      "Epoch 34/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.3013 - accuracy: 0.8470 - val_loss: 2.9139 - val_accuracy: 0.5993\n",
      "Epoch 35/50\n",
      "1543/1543 [==============================] - 24s 16ms/step - loss: 0.2948 - accuracy: 0.8495 - val_loss: 2.8121 - val_accuracy: 0.6096\n",
      "Epoch 36/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.2953 - accuracy: 0.8503 - val_loss: 2.5628 - val_accuracy: 0.6052\n",
      "Epoch 37/50\n",
      "1543/1543 [==============================] - 25s 16ms/step - loss: 0.2905 - accuracy: 0.8535 - val_loss: 2.8924 - val_accuracy: 0.5981\n",
      "Epoch 38/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.2874 - accuracy: 0.8536 - val_loss: 3.2033 - val_accuracy: 0.5686\n",
      "Epoch 39/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.2823 - accuracy: 0.8565 - val_loss: 3.7442 - val_accuracy: 0.6099\n",
      "Epoch 40/50\n",
      "1543/1543 [==============================] - 24s 16ms/step - loss: 0.2797 - accuracy: 0.8580 - val_loss: 3.3574 - val_accuracy: 0.6142\n",
      "Epoch 41/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.2776 - accuracy: 0.8586 - val_loss: 3.7192 - val_accuracy: 0.5889\n",
      "Epoch 42/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.2741 - accuracy: 0.8607 - val_loss: 3.6625 - val_accuracy: 0.6020\n",
      "Epoch 43/50\n",
      "1543/1543 [==============================] - 24s 16ms/step - loss: 0.2698 - accuracy: 0.8642 - val_loss: 3.9131 - val_accuracy: 0.6095\n",
      "Epoch 44/50\n",
      "1543/1543 [==============================] - 23s 15ms/step - loss: 0.2660 - accuracy: 0.8636 - val_loss: 4.3438 - val_accuracy: 0.6106\n",
      "Epoch 45/50\n",
      "1543/1543 [==============================] - 21s 14ms/step - loss: 0.2635 - accuracy: 0.8658 - val_loss: 3.5535 - val_accuracy: 0.5605\n",
      "Epoch 46/50\n",
      "1543/1543 [==============================] - 22s 14ms/step - loss: 0.2603 - accuracy: 0.8683 - val_loss: 3.8766 - val_accuracy: 0.6161\n",
      "Epoch 47/50\n",
      "1543/1543 [==============================] - 22s 14ms/step - loss: 0.2611 - accuracy: 0.8666 - val_loss: 3.8195 - val_accuracy: 0.6155\n",
      "Epoch 48/50\n",
      "1543/1543 [==============================] - 22s 14ms/step - loss: 0.2558 - accuracy: 0.8695 - val_loss: 3.7860 - val_accuracy: 0.6174\n",
      "Epoch 49/50\n",
      "1543/1543 [==============================] - 22s 14ms/step - loss: 0.2567 - accuracy: 0.8697 - val_loss: 4.5219 - val_accuracy: 0.6118\n",
      "Epoch 50/50\n",
      "1543/1543 [==============================] - 27s 18ms/step - loss: 0.2534 - accuracy: 0.8715 - val_loss: 3.5766 - val_accuracy: 0.6230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23511bdf220>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = [i for i in df_final[df_final['Type'] == 'Train']['Tokens'].values]\n",
    "x_test = [i for i in df_final[df_final['Type'] == 'Test']['Tokens'].values]\n",
    "\n",
    "x_train = pad_sequences(x_train, padding='post',maxlen = max(df_final['num_words']))\n",
    "x_test = pad_sequences(x_test, padding='post',maxlen = max(df_final['num_words']))\n",
    "\n",
    "# Encoder de las emociones\n",
    "Y = np.where(df_final['Target'].values == 'neutral', True, False)\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(np.array(Y).reshape(-1,1))\n",
    "\n",
    "y_train = np.where(df_final[df_final['Type'] == 'Train']['Target'].values  == 'neutral', True, False)\n",
    "y_test = np.where(df_final[df_final['Type'] == 'Test']['Target'].values  == 'neutral', True, False)\n",
    "y_train = encoder.transform(np.array(y_train).reshape(-1,1)).toarray()\n",
    "y_test = encoder.transform(np.array(y_test).reshape(-1,1)).toarray()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = max_value, output_dim = 16, input_length=x_train.shape[1]))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.4, verbose=0, patience=5, min_lr=0.0000001)\n",
    "es = EarlyStopping(monitor='val_loss', patience=50)\n",
    "model.fit(x_train, y_train, epochs= 50, validation_data=(x_test, y_test), callbacks=[es])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "SER-WHISPER",
   "language": "python",
   "name": "ser-whisper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
